{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7YynbeMXvrq"
      },
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV67zf7wXvr2"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0leTKuFXvr3"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9A4fKdcXvr4"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWran3wgXvr5"
      },
      "source": [
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'Elastic Net': ElasticNet(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Isotonic': IsotonicRegression(),\n",
        "    'Gaussian Process': GaussianProcessRegressor(),\n",
        "    'Simpler Neural Network': MLPRegressor(early_stopping=True),\n",
        "    'XGBoost': XGBRegressor(verbosity=0)\n",
        "}\n",
        "\n",
        "parameters = {\n",
        "    'Ridge': {'alpha': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]},\n",
        "    'Lasso': {'alpha': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]},\n",
        "    'Elastic Net': {'alpha': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]},\n",
        "    'Random Forest': {'bootstrap':[True, False], 'n_estimators':[10, 30, 100, 300]},\n",
        "    'Simpler Neural Network': {'hidden_layer_sizes': [30, 100, 300], 'activation': ['logistic', 'tanh', 'relu']}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqyZ0H3fXvr5"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def experimental(X, y, filename=None):\n",
        "    ans = {}\n",
        "    for c in [m for m in models.keys() if m not in list(parameters.keys())]:\n",
        "        start = time.process_time()\n",
        "        \n",
        "        pipeline = Pipeline([('transformer', StandardScaler()), ('estimator', models[c])])\n",
        "        ans[c] = cross_validate(pipeline, X, y)\n",
        "        print('Elapsed time of {} is {:.6f} seconds.'.format(c, time.process_time() - start))\n",
        "\n",
        "    for c in parameters.keys():\n",
        "        start = time.process_time()\n",
        "        \n",
        "        clf = Pipeline([('transformer', StandardScaler()), \n",
        "                        ('estimator', GridSearchCV(models[c], param_grid=parameters[c]))]).fit(X, y) # Grid search\n",
        "        \n",
        "        pipeline = Pipeline([('transformer', StandardScaler()), ('estimator', clf)])\n",
        "        ans[c] = cross_validate(pipeline, X, y)\n",
        "        print('Elapsed time of {} is {:.6f} seconds.'.format(c, time.process_time() - start))\n",
        "    \n",
        "    pickle.dump(ans, open(filename, \"wb\" ))\n",
        "    return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQda0j1Xvr6",
        "outputId": "c9fc038d-5f53-4ed3-f086-ee10ca03ddf6"
      },
      "source": [
        "ans = experimental(X, y, 'file')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time of Linear Regression is 61.585555 seconds.\n",
            "Elapsed time of XGBoost is 2.523960 seconds.\n",
            "Elapsed time of Ridge is 438.911417 seconds.\n",
            "Elapsed time of Lasso is 1273.599287 seconds.\n",
            "Elapsed time of Elastic Net is 2010.287056 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}